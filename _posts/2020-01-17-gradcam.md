---
layout: post
title: "Grad-CAM"
author: jihoon
date: 2020-01-11 18:30
tags: [localization, CNN, Grad-CAM, CAM]
---


# Introduction

Image Classification은 Convolutional Deep Neural Network를 활용하는 대표적인 문제들 중 하나입니다. 이와 관련된 유명한 대회로 ILSVRC (ImageNet Large Scale Visual Recognition Challenge) 가 있습니다. ImageNet 데이터베이스의 데이터를 이용하여 대회가 이루어지는데, 약 백만 장의, 천 개의 카테고리로 분류된 training image들을 이용하여 각 test image에 대해서 어떤 카테고리에 속할 지 잘 예측하는 것을 목표로 합니다. 이 대회에서 널리 알려진 네트워크 구조인 AlexNet, GoogLeNet, VGGNet, ResNet 모델 등이 제안되기도 하였습니다.

고양이가 있는 사진이 '고양이' 카테고리로 분류되어 있다고 해 봅시다. 그렇다면 사람은 고양이를 있는 위치를 보고 사진이 '고양이' 카테고리로 분류되어 있다고 생각할 것입니다. 그렇다면 과연 CNN은 어떻게 카테고리를 예측할까요?

이러한 궁금증을 해결하기 위해 여러 솔루션들이 제안되었습니다. 이 글에서는 가장 널리 알려진 솔루션 중 하나인 CAM (Class Activation Map)과 이후에 나온 Grad-CAM (Gradient-weighted CAM) 에 대해서 다루도록 하겠습니다.



# CAM (Class Activation Map)

Convolutional Layer를 사용한 모델은 (특히) 이미지 처리를 할 때 Fully-connected Layer를 사용할 때에 비해 많은 task에서 좋은 성능을 보여주었습니다. 또한 Convolutional layer는 layer를 거친 후에도 spatial information을 보존하는데 비해, Fully-Connected layer는 flatten 과정을 거치게 되므로 spatial information의 손실이 발생합니다.

많은 Image Classification 모델들은 여러 층의 Convolutional layer를 거친 후, Fully-Connected layer를 통해서 classification을 진행합니다. 반면에 CAM은 Convolutional layer를 거친 후 Fully-Connected Layer를 바로 사용하는 대신 GAP (Global Average Pooling) 를 사용한 후 마지막으로 하나의 Fully-Connected Layer를 사용합니다. GAP는 Average Pooling Layer에서 kernel size가 layer의 input size와 동일한 경우로, [Network In Network](https://arxiv.org/abs/1312.4400) 논문에서 parameter 개수를 줄여 overfitting을 방지하기 위한 아이디어로 제안되었습니다. 이 논문에서는 GAP가 overfitting 뿐만 아니라 특정 카테고리에 대한 부분을 효과적으로 localization하는 데에 사용할 수 있다는 것을 보였습니다.



## CAM 계산

CAM을 구하기 위해서는 마지막 convolutional layer의 output (= GAP의 input) 과 바로 뒤의 Fully-Connected Layer의 weight, 이렇게 두 가지 정보가 필요합니다. $$f_k(x, y)$$를 GAP의 input의 $$k$$번째 unit의 $$(x, y)$$ 좌표에 해당하는 값이라고 하고, $$w_{k}^{c}$$를 Fully-Connected layer에서 input의 $$k$$번째 unit과 output의 $$c$$번째 (class)에 대응되는 weight이라고 정의합시다.

그렇다면 softmax를 거치기 전 Fully-Connected layer를 거친 후 $$c$$번째에 대응되는 output $$S_{c}$$는 아래와 같이 나타낼 수 있습니다:

$$S_c = \sum_{k} w_{k}^{c} \sum{x, y} f_k(x, y) = \sum{k} \sum{x, y} w_{k}^{c} f_k(x, y) = \sum{x, y} \sum{k}  w_{k}^{c} f_k(x, y)$$



## CAM 구현

편의 상 [VGG 모델](https://arxiv.org/abs/1409.1556) 에서 CAM을 사용한다고 가정하고 설명을 진행하겠습니다. 먼저 끝 부분의 max pooling layer와 fully connected layer를 제거하고, CAM에 사용할 마지막 Convolutional layer와 Global Average Pooling 그리고 Fully-Connected Layer를 붙여주면 됩니다.

```python
from torch import nn

class VGG16_CAM(nn.Module):
	def __init__(self):
		super(VGG16_CAM, self).__init__()
		# [16개의 Convolutional Layer]
		# 마지막 Convolutional Layer
		self.CAM_conv = nn.Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)
        self.CAM_relu = nn.ReLU(inplace=True)
        # Global Average Pooling과 CAM 계산 및 classification을 위한 Fully-Connected Layer
        self.CAM_gap = nn.AvgPool2d(kernel_size=14, stride=14)
        self.CAM_fc = nn.Linear(in_features=1024, out_features=1000, bias=True)
```

 그 후 위에 설명한 식대로 

```python
self.model.CAM_relu.register_forward_hook(self.forward_hook)

def forward_hook(self, _, input, output):
	self.forward_result = torch.squeeze(output)
```

```python
cam = torch.tensordot(self.model.CAM_fc.weight[target_label, :], self.forward_result.squeeze(), dims=1).squeeze()

# Use only positive value and normalize
cam = (cam + torch.abs(cam)) / 2
cam /= torch.max(cam)

# Bilinear-upsample (14*14 -> 224*224)
cam = torch.nn.Upsample(scale_factor=16, mode='bilinear')(cam.unsqueeze(0).unsqueeze(0))
return cam.squeeze().cpu().detach().numpy()
```



# Grad-CAM

CAM의 가장 큰 단점은 바로 Global Average Pooling layer가 반드시 필요하다는 점입니다. GAP이 이미 포함되어 있는 GoogLeNet의 경우에는 문제가 없겠지만, 그렇지 않은 경우에는 마지막 convolutional layer 뒤에 GAP를 붙여서 다시 fine-tuning 해야 한다는 문제가 생기고, 약간의 성능 감소를 동반하는 문제가 있습니다. 또한, 같은 이유로 마지막 layer에 대해서만 CAM 결과를 얻을 수 있습니다. 

Grad-CAM은 gradient를 이용하여 Global Average Pooling에 의존하지 않는 아이디어를 제안했습니다. 이에 따라 자연스럽게 CAM의 문제점을 해결하게 되었습니다. 즉, Grad-CAM을 사용하면, 어떤 Convolutional Layer를 가진 모델이어도 모델 구조의 수정 없이 CAM 결과를 얻을 수 있습니다.



## Guided Grad-CAM





# 마무리

aaaa



# Reference

[(CAM paper) Learning Deep Features for Discriminative Localization](http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf)

[Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391)